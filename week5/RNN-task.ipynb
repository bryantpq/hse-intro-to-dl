{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5739945128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: #'-ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "n_tokens: 56\n"
     ]
    }
   ],
   "source": [
    "tokens = ''.join(sorted(''.join(set(''.join(names))) + '#'))\n",
    "print('Tokens:' + tokens)\n",
    "\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '#': 1, \"'\": 2, '-': 3, 'A': 4, 'B': 5, 'C': 6, 'D': 7, 'E': 8, 'F': 9, 'G': 10, 'H': 11, 'I': 12, 'J': 13, 'K': 14, 'L': 15, 'M': 16, 'N': 17, 'O': 18, 'P': 19, 'Q': 20, 'R': 21, 'S': 22, 'T': 23, 'U': 24, 'V': 25, 'W': 26, 'X': 27, 'Y': 28, 'Z': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
     ]
    }
   ],
   "source": [
    "#token_to_id = ### YOUR CODE HERE: create a dictionary of {symbol -> its index in tokens}\n",
    "token_to_id = {j: i for i, j in enumerate(tokens)}\n",
    "print(token_to_id)\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[ 0  4 31 30 36 30 34 41  1]\n",
      " [ 0 10 41 44 47 54  1  1  1]\n",
      " [ 0 19 47 38 48 48 38 34  1]\n",
      " [ 0 10 38 44 51 30 43 43 34]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "#get_h_next = ### YOUR CODE HERE\n",
    "get_h_next = Dense(rnn_num_units, activation='tanh', input_shape=(rnn_num_units + embedding_size,))\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "#get_probas = ### YOUR CODE HERE\n",
    "get_probas = Dense(n_tokens, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = concatenate([x_t_emb, h_t], axis=1)\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 16, 56)\n",
      "(?, 15, 56)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "print(predicted_probas.shape)\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]\n",
    "print(predicted_probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(15), Dimension(56)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probas.shape\n",
    "# 30720 / (15 * 64) = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "\n",
    "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56f5167c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fatmit\n",
      " Gali\n",
      " nhhvero\n",
      " Feiducen\n",
      " Vazhi\n",
      " Jarliy\n",
      " Lpeltie\n",
      " Dalcis\n",
      " Lew\n",
      " Smay\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Brigce\n",
      " Brrin\n",
      " Brory\n",
      " Brsree\n",
      " Brinni\n",
      " Branle\n",
      " Brasla\n",
      " Brlelile\n",
      " Bremtan\n",
      " Bron\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Br'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"SbQaUIXKZvqTzL9a\"\n",
    "COURSERA_EMAIL = \"bryanquah@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f2402758c148679ba0a358f453904c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 56)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
